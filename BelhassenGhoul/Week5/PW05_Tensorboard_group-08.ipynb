{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662e50da",
   "metadata": {},
   "source": [
    "**Group-08**<br/>\n",
    "<font style=\"color:red\"> **Belhassen Ghoul <br/> Robin Ehrensperger <br/> Dominic Diedenhofen**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ec37d7-f7cb-4646-a2dd-9dab66239a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8a986-1cb2-483b-9bd8-0f71d69fa9e8",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba6b0c6-3f55-40dd-ba32-6f6aad8f1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.mnist.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.mnist.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c2da4ed-af9a-4fc7-b59f-135b51241d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data, validation_data = torch.utils.data.random_split(training_data, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b30c81-d89f-4947-aa09-ab8c70dd262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data),len(validation_data),len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ff404-5b8a-4f63-9730-d6708d2ac8d1",
   "metadata": {},
   "source": [
    "### MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61b15df-a84b-483d-9365-d8f66390b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(units = [28*28,250,80,10]):\n",
    "    seq = [torch.nn.Flatten()]\n",
    "    for i in range(len(units)-2):\n",
    "        seq.append(torch.nn.Linear(units[i],units[i+1]))\n",
    "        seq.append(torch.nn.Sigmoid())\n",
    "    seq.append(torch.nn.Linear(units[-2],units[-1]))\n",
    "    return torch.nn.Sequential(*seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4bfd0a4-999c-4690-9ef3-b5ee1ab26c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 250]         196,250\n",
      "           Sigmoid-3                  [-1, 250]               0\n",
      "            Linear-4                   [-1, 80]          20,080\n",
      "           Sigmoid-5                   [-1, 80]               0\n",
      "            Linear-6                   [-1, 10]             810\n",
      "================================================================\n",
      "Total params: 217,140\n",
      "Trainable params: 217,140\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.83\n",
      "Estimated Total Size (MB): 0.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "from torchsummary import summary\n",
    "summary(model, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa393a-9f99-48f4-996d-cf8d2a3b8cd5",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Implement the training / evaluation loop\n",
    "\n",
    "Remember training / validation cost and accuracy per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172c91d1-4c9e-413a-bfff-01f51a1e323a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval(model, optimizer, nepochs, training_loader, test_loader, scheduler=None):\n",
    "    cost_hist = []\n",
    "    cost_hist_test = []\n",
    "    acc_hist = []\n",
    "    acc_hist_test = []\n",
    "\n",
    "    cost_ce = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    runningLoss = 0.0 \n",
    "    runningCorrect = 0.0\n",
    "    for epoch in range(nepochs):\n",
    "        model.train()\n",
    "        size = len(training_loader.dataset)\n",
    "        nbatches = len(training_loader)\n",
    "        size_test = len(test_loader.dataset)\n",
    "        nbatches_test = len(test_loader)\n",
    "        cost, acc = 0.0, 0.0\n",
    "        for batch, (X, Y) in enumerate(training_loader):\n",
    "            pred = model(X)\n",
    "            loss = cost_ce(pred, Y)\n",
    "            cost += loss.item()\n",
    "            acc += (pred.argmax(dim=1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "            # gradient, parameter update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runningLoss += loss.item()\n",
    "            runningCorrect += (pred.argmax(dim=1) == Y).type(torch.float).sum().item()\n",
    "            writer.add_scalar(\"training loss\", runningLoss, epoch*nbatches+batch)\n",
    "            writer.add_scalar(\"accuracy loss\", runningCorrect, epoch*nbatches+batch)\n",
    "            runningLoss = 0.0\n",
    "            runningCorrect = 0.0\n",
    "\n",
    "            writer.add_graph(model, X)\n",
    "            writer.close()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        cost /= nbatches\n",
    "        acc /= size\n",
    "    \n",
    "        model.eval()\n",
    "        cost_test, acc_test = 0.0, 0.0        \n",
    "        with torch.no_grad():\n",
    "            for X, Y in test_loader:\n",
    "                pred = model(X)\n",
    "                cost_test += cost_ce(pred, Y).item()\n",
    "                acc_test += (pred.argmax(dim=1) == Y).type(torch.float).sum().item()\n",
    "        cost_test /= nbatches_test\n",
    "        acc_test /= size_test\n",
    "\n",
    "        print(\"Epoch %i: %f, %f, %f, %f\"%(epoch, cost, acc, cost_test, acc_test))\n",
    "        cost_hist.append(cost)\n",
    "        cost_hist_test.append(cost_test)\n",
    "        acc_hist.append(acc)\n",
    "        acc_hist_test.append(acc_test)\n",
    "    return cost_hist, cost_hist_test, acc_hist, acc_hist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1fa1c2b-50d7-4b23-91c8-c47eec5fc8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.899447, 0.650440, 0.596000, 0.792300\n",
      "Epoch 1: 0.514793, 0.810700, 0.597713, 0.778100\n",
      "Epoch 2: 0.452955, 0.834280, 0.447927, 0.839300\n",
      "Epoch 3: 0.415104, 0.847440, 0.459456, 0.835700\n",
      "Epoch 4: 0.387457, 0.859180, 0.387945, 0.857200\n",
      "Epoch 5: 0.368129, 0.863140, 0.572586, 0.777200\n",
      "Epoch 6: 0.353074, 0.869180, 0.573192, 0.781900\n",
      "Epoch 7: 0.339449, 0.874460, 0.332906, 0.873000\n",
      "Epoch 8: 0.326345, 0.878520, 0.341865, 0.872200\n",
      "Epoch 9: 0.316329, 0.883380, 0.879270, 0.690100\n",
      "Epoch 10: 0.308295, 0.885420, 0.471664, 0.838200\n",
      "Epoch 11: 0.301618, 0.887040, 0.340638, 0.875700\n",
      "Epoch 12: 0.291519, 0.891540, 0.375130, 0.863500\n",
      "Epoch 13: 0.285340, 0.893400, 0.427403, 0.851800\n",
      "Epoch 14: 0.279000, 0.895840, 0.350703, 0.863600\n",
      "Epoch 15: 0.273223, 0.897700, 0.362765, 0.864400\n",
      "Epoch 16: 0.265776, 0.900200, 0.301215, 0.890400\n",
      "Epoch 17: 0.259582, 0.902040, 0.344069, 0.873100\n",
      "Epoch 18: 0.254696, 0.903960, 0.385500, 0.857800\n",
      "Epoch 19: 0.249713, 0.906420, 0.292794, 0.893500\n"
     ]
    }
   ],
   "source": [
    "nbatch = 64\n",
    "nepochs =20\n",
    "\n",
    "training_loader = DataLoader(training_data, batch_size=nbatch, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=nbatch, shuffle=True)\n",
    "\n",
    "model = mlp()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.8)\n",
    "\n",
    "cost_hist, cost_hist_test, acc_hist, acc_hist_test = train_eval(model, optimizer, nepochs, training_loader, validation_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f24c35-9def-48ba-a505-20b99d450584",
   "metadata": {},
   "source": [
    "### Plots and Comments (for the different steps described above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b1ab6cb-7787-4f18-8763-ae231c610c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(training_loader)\n",
    "example_data, example_labels = examples.next()\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image(\"fashon\",img_grid)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
