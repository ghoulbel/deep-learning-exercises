{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c76f8e4",
   "metadata": {},
   "source": [
    "**Group-08**<br/>\n",
    "<font style=\"color:red\"> **Belhassen Ghoul <br/> Robin Ehrensperger <br/> Dominic Diedenhofen**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7d3c3737-73dc-481a-8cf0-afb3657ca3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de7e72-0814-405b-8c2c-cefa78d66dc0",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "A Model here consists of a succession of layers.\n",
    "\n",
    "Each layer is implemented as a class with the following API-methods:\n",
    "\n",
    "`forward(torch.tensor)`: Computes the forward pass through the layer, i.e. $x\\rightarrow a$<br> and keeps the information needed for computing the backward pass as member variables. \n",
    "`backward(torch.tensor)`: Computes the backward pass through the layer in form of the derivatives, i.e. $da \\rightarrow dx$. On the fly, it also computes the derivatives w.r.t. the parameters of the layer and keeps them as member variables. It assumes that `forward` method has been run before. <br>\n",
    "`update(lr)`: Updates the parameters of the layer in accordance with vanilla gradient descent and scalar learning rate `lr`. It assumes that the `forward` and the `backward`-pass has been run before.  \n",
    "\n",
    "The tensors defined as inputs to the `forward`/`backward`-method are two dimensional with the sample index in the first and the the feature index in the second dimension. \n",
    "\n",
    "For fully connected layers with activation function $s(\\cdot)$ the formulas are given as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdbdc5-d75a-416b-a5df-dfd3ef1fca05",
   "metadata": {},
   "source": [
    "__Forward path:__\n",
    "\n",
    "$X_{i,j}$: Tensor with shape $(n_b,n_x)$ where $n_b$ is the number of samples in the batch and $n_x$ the number of input features (for MNIST: 784).\n",
    "\n",
    "$Z_{i,j} = \\sum_k X_{i,k} W_{j,k} \\qquad (Z = X \\cdot W^T + b)$ $\\qquad$ ($W$ a tensor of shape $(n_h,n_x)$)\n",
    "\n",
    "$A_{i,j} = s(Z_{i,j}) \\qquad\\qquad (A = s(Z))$\n",
    "\n",
    "__Backward path:__ (with $n_b$ the number of samples in a batch)\n",
    "\n",
    "$dx_{i,k} = \\frac{\\partial L}{\\partial x_{i,k}} = \\sum_j \\frac{\\partial L}{\\partial a_{i,j}} \\frac{\\partial a_{i,j}}{\\partial x_{i,k}} = \\sum_j da_{i,j} s^\\prime(z_{i,j})\\cdot \\frac{\\partial z_{i,j}}{\\partial x_{i,k}} = \\sum_j da_{i,j} s^\\prime(z_{i,j}) W_{j,k}$<br>\n",
    "\n",
    "$dW_{k,j} = \\frac{\\partial L}{\\partial W_{k,j}} = \\frac{1}{n_b}\\sum_i da_{i,k}\\frac{\\partial a_{i,k}}{\\partial W_{k,j}} = \\frac{1}{n_b}\\sum_j da_{i,k} s^\\prime(z_{i,k}) \\frac{\\partial z_{i,k}}{\\partial W_{k,j}} = \\frac{1}{n_b}\\sum_j da_{i,k} s^\\prime(z_{i,k}) x_{i,j}$<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad958e2-bb1e-493f-9c4d-40514e20c479",
   "metadata": {},
   "source": [
    "__Parameter Initialisation__ \n",
    "\n",
    "The parameters need to be initialised which will be a topic later in the course. For now use the following rules: \n",
    "* weights normally distributed with mean $0$ and stdev $1/\\sqrt{n_h}$\n",
    "* bias initialized with zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d7916-88e9-4cc9-91e8-ec600741370d",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Important Note on the Implementation</span>\n",
    "\n",
    "Make sure that all the tensors used anywhere in the model components below have `requires_grad=False`.\n",
    "Autograd functionality is not allowed for computing the gradients. - Autograd will be used below for testing whether your implementation is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae0f20-6928-481d-96b2-02cbfa298760",
   "metadata": {},
   "source": [
    "### Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c81dc286-9543-4278-a174-6fbba6be026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer():\n",
    "    def __init__(self, nx, nh):\n",
    "        \"\"\"\n",
    "        nx -- number of input features, i.e. shape of input tensors x given by (*,nb_input)\n",
    "        nh -- number of output features, i.e. shape of output tensor z given by (*,nb_hidden)\n",
    "        \"\"\"    \n",
    "        self.nx = nx\n",
    "        self.nh = nh\n",
    "        self.w = torch.empty(nh, nx).normal_(0, 1./math.sqrt(self.nh))\n",
    "        self.b = torch.zeros(nh)\n",
    "        self.dw = torch.zeros_like(self.w)\n",
    "        self.db = torch.zeros_like(self.b)\n",
    "        self.x = None\n",
    "        self.dx = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes the forward pass through the layer\n",
    "        x -- input tensor\n",
    "        returns z \n",
    "        \"\"\"\n",
    "        ### YOUR CODE START ###\n",
    "        self.x = x\n",
    "        z = torch.matmul(x, self.w.T)+ self.b\n",
    "        return z\n",
    "        ### YOUR CODE END ###\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        \"\"\"\n",
    "        Computes the backward pass through the layer incl. the derivatives w.r.t. input x (dx), weight w (dw) and bias b (db).\n",
    "        dz -- tensor with the backprop'd error signal with the same shape as z.         \n",
    "        returns dx\n",
    "        \"\"\"\n",
    "        assert len(dz.shape)==2 and dz.shape[1] == self.nh\n",
    "        ### YOUR CODE START ###\n",
    "        dx = torch.matmul(dz,self.w)\n",
    "\n",
    "        self.dw = torch.mean(dz.view(-1,self.nh,1) * self.x.view(-1,1,self.nx),dim=0)\n",
    "        self.db = torch.mean(dz,dim=0)\n",
    "        return dx\n",
    "        ### YOUR CODE END ###\n",
    "            \n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Updates the parameters of the model (weights w and bias b) with the gradient w.r.t. w and b and learning rate.\n",
    "        returns None\n",
    "        \"\"\"\n",
    "        ### YOUR CODE START ###\n",
    "        self.w = self.w - (lr * self.dw)\n",
    "        self.b = self.b - (lr * self.db)  \n",
    "        ### YOUR CODE END ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9fd5b-a7b6-4a74-bd71-ab9bc1c79263",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">SHAPE TEST:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "28d46297-caf7-4b69-bc8f-9b32eb25590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearLayer(3,4)\n",
    "assert (4,3) == linear.w.shape\n",
    "assert (4,)  == linear.b.shape\n",
    "\n",
    "x = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "a = linear.forward(x)\n",
    "assert (2,4) == a.shape\n",
    "\n",
    "dz = torch.tensor([[1.,1,1,1],[2.,2,2,2]])\n",
    "dx = linear.backward(dz)\n",
    "assert (2,3) == dx.shape\n",
    "assert (4,3) == linear.dw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e7383-adf3-4822-9d99-644b9eb33e07",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "__Sigmoid__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ae86ae0a-0382-4349-acb9-6b1e29be36ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SigmoidActivation():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.z = None\n",
    "    \n",
    "    def forward(self, z):\n",
    "        ### YOUR CODE START ###\n",
    "        self.z = z\n",
    "        sigmoid = 1/(1+torch.exp(-z))\n",
    "        return sigmoid\n",
    "        ### YOUR CODE END ###\n",
    "\n",
    "    def backward(self, da):\n",
    "        ### YOUR CODE START ###\n",
    "        sigmoid = self.forward(self.z)\n",
    "        dx = sigmoid*(1-sigmoid)*da\n",
    "        return dx\n",
    "        ### YOUR CODE END ###\n",
    "            \n",
    "    def update(self, lr):\n",
    "        ### YOUR CODE START ###\n",
    "        self.z -= lr * self.backward(self.z) \n",
    "        ### YOUR CODE END ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949cda-b92b-4c17-a868-73dec9fd1718",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Now implement an MLP as a succession of layers - linear layers and non-linear activation layers.\n",
    "For creating an instance, you will pass the following arguments: \n",
    "* nx: number of input features\n",
    "* nunits: list of number of units in the hidden layers including the output layer\n",
    "\n",
    "Add a list of layers as member variable.\n",
    "\n",
    "Use just a linear layer at the end. Further below we will use a CE loss which is based on the finally output logit values (see lecture of week 2) where the softmax probabilities are implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ee66c47a-d587-47af-8d10-384a157948f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \n",
    "    def __init__(self, nx, nunits):\n",
    "        self.nx = nx\n",
    "        self.nlayers = len(nunits)\n",
    "        self.nunits = nunits\n",
    "        self.nunits.insert(0,nx)\n",
    "        self.nclasses = self.nunits[-1]\n",
    "        self.layers = []\n",
    "        \n",
    "        ### YOUR CODE START ###\n",
    "        # instantiate the different layers (linear and activations)\n",
    "        \n",
    "        self.layers.append(LinearLayer(self.nx, self.nlayers))\n",
    "        self.layers.append(SigmoidActivation())\n",
    "        self.layers.append(LinearLayer(self.nlayers,self.nclasses))\n",
    "        \n",
    "        \n",
    "        ### YOUR CODE END ###\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x - input tensor        \n",
    "        returns output tensor of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE START ###\n",
    "\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "        \n",
    "        ### YOUR CODE END ###\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        \"\"\"\n",
    "        dy - derivative w.r.t. output tensor\n",
    "        \n",
    "        returns derivative with respect to the input tensor of the model; \n",
    "        on the fly compute all the derivatives w.r.t. parameters of the model\n",
    "        \"\"\"        \n",
    "        ### YOUR CODE START ###\n",
    "        for l in reversed(self.layers):\n",
    "            dy = l.backward(dy)\n",
    "        return dy\n",
    "        ### YOUR CODE END ###\n",
    "    \n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Update the parameters with the given (stored) derivatives w.r.t. model parameters by using the given learning rate. \n",
    "        \"\"\"\n",
    "        ### YOUR CODE START ###\n",
    "        \n",
    "        for l in self.layers:\n",
    "            l.update(lr)\n",
    "        \n",
    "        ### YOUR CODE END ###\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0859db-1d16-4652-8549-b09fa695602b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">SHAPE TEST:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6020ece6-ccfe-4242-b72c-4d00c0c1f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 2\n",
    "nunits = [3,4]\n",
    "mlp = MLP(nx,nunits)\n",
    "assert 3 == len(mlp.layers)\n",
    "\n",
    "x = torch.tensor([[1.,2],[3,4]])\n",
    "a = mlp.forward(x)\n",
    "assert (2,4) == a.shape\n",
    "\n",
    "da = torch.tensor([[1.,1,1,1],[2.,2,2,2]])\n",
    "dx = mlp.backward(da)\n",
    "assert (2,2) == dx.shape\n",
    "\n",
    "nx = 2\n",
    "nunits = [3,4]\n",
    "mlp = MLP(nx,nunits)\n",
    "assert 3 == len(mlp.layers)\n",
    "\n",
    "x = torch.tensor([[1.,2],[3,4]])\n",
    "a = mlp.forward(x)\n",
    "assert (2,4) == a.shape\n",
    "\n",
    "da = torch.tensor([[1.,1,1,1],[2.,2,2,2]])\n",
    "dx = mlp.backward(da)\n",
    "assert (2,2) == dx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f5f56-97d9-47c3-b0c8-ee3699c2eaca",
   "metadata": {},
   "source": [
    "### Regression Test\n",
    "\n",
    "Create a regression testing that allows you to test your implementation by regressing against the gradients computed by pytorch's autograd.\n",
    "\n",
    "Below you find two functions that may be helpful in \n",
    "1. creating a reference model from the given model - makes sure that in the reference model the exact same initialized parameters are used; furthermore, that teh parameters of the linear layers (w,b) are specified as tensors with `requires_grad=True`. \n",
    "2. comparing the derivatives w.r.t. parameters for model and refmodel. It assumes that for both, model and refmodel, backprop has been executed. For the model, it means that `backward()`has been executed - for the ref model, only `forward` has been executed, but `backward` applied to the output tensor of the refmodel. For the remodel, we use `grad` of the weights and bias tensors, for the model the parameters `dw` and `db` as basis for the comparison.\n",
    "\n",
    "<span style=\"color:red\">Adjust these methods to make them compliant with your model - it uses internals of our implementation.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3e33f3c4-ab4a-4271-9d5f-39cc9f53ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_refmodel(model):\n",
    "    refmodel = MLP(model.nx, model.nunits[1:])\n",
    "    for i,layer in enumerate(model.layers):\n",
    "        if isinstance(layer, LinearLayer):\n",
    "            refmodel.layers[i].w = model.layers[i].w.detach().clone()\n",
    "            refmodel.layers[i].w.requires_grad_()\n",
    "            refmodel.layers[i].b = model.layers[i].b.detach().clone()\n",
    "            refmodel.layers[i].b.requires_grad_()\n",
    "    return refmodel\n",
    "\n",
    "def test_params(model, refmodel, digits=8):\n",
    "    for i,layer in enumerate(model.layers):\n",
    "        if isinstance(layer, LinearLayer):\n",
    "            try:\n",
    "                xxref = refmodel.layers[i].w.grad.detach().numpy()\n",
    "                xx = model.layers[i].dw.numpy()\n",
    "                np.testing.assert_array_almost_equal(xx, xxref, decimal=digits, err_msg=\"Error: layer %i\"%i)\n",
    "                xxref = refmodel.layers[i].b.grad.detach().numpy()\n",
    "                xx = model.layers[i].db.numpy()\n",
    "                np.testing.assert_array_almost_equal(xx, xxref, decimal=digits, err_msg=\"Error: layer %i\"%i)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"test failed - reason:\",e) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf6929-9a82-4ec6-94d1-90ccad1752e0",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> REGRESSION TEST</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f80d2e20-4fb6-4ed9-ab7f-670d9aca8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "nx = 10\n",
    "x = torch.randn(nx).reshape(-1,nx)\n",
    "\n",
    "# model instance\n",
    "nunits = [20,40,1]\n",
    "mlp = MLP(nx,nunits)\n",
    "\n",
    "# forward and backward pass\n",
    "z = mlp.forward(x)\n",
    "dz = torch.tensor([1.,1.]).reshape(-1,1)\n",
    "dx = mlp.backward(dz)\n",
    "\n",
    "# create ref model\n",
    "mlpref = create_refmodel(mlp)\n",
    "\n",
    "# only use the forward method of the ref model - and apply backward to the output tensor.\n",
    "zref = mlpref.forward(x) \n",
    "zref.backward()\n",
    "\n",
    "# compare the derivatives computed by your model with the grad computed by pytorch's autograd\n",
    "test_params(mlp, mlpref, digits=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d6187-bbbd-4bf1-ae3f-929342eeb39d",
   "metadata": {},
   "source": [
    "### Cost \n",
    "\n",
    "Use the cross-entropy cost function directly defined on the basis of the logits - which implicitly includes a softmax calculation (see lecture notes of week 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f26dbc1b-697b-46cd-94de-d78e701921f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CELoss():\n",
    "    \n",
    "    def value(self, z, y):\n",
    "        \"\"\"\n",
    "        z -- tensor of shape (number of samples, number of classes) with the final logits of the model. \n",
    "        y -- tensor of shape (number of samples) with the label values.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE START ###\n",
    "        cost = torch.nn.CrossEntropyLoss()\n",
    "        loss = torch.mean(cost(z,y))*y.shape[0]\n",
    "        return loss\n",
    "\n",
    "        \"\"\"m = y.shape[0]\n",
    "        exp = np.exp(z)   \n",
    "        p = exp/(torch.sum(exp))\n",
    "        log_likelihood = -torch.log(p[range(m),y])\n",
    "        loss = torch.sum(log_likelihood) \n",
    "        return loss\"\"\"\n",
    "        ### YOUR CODE END ###\n",
    "\n",
    "    def derivative(self, z, y):\n",
    "        ### YOUR CODE START ###\n",
    "        softmax = torch.softmax(z,1)\n",
    "\n",
    "        m = y.shape[0]\n",
    "        grad = softmax\n",
    "        grad[range(m),y] -= 1\n",
    "        grad = grad\n",
    "        return grad\n",
    "        ### YOUR CODE END ###\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9e9e731f-7163-4cc9-a5b0-5c2a000ef8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CELoss()\n",
    "ypred = torch.log(torch.tensor([[0.5,0.4,0.1],[0.2,0.1,0.7]])).reshape(-1,3) # -> logits z\n",
    "y = torch.tensor([1,2]).reshape(-1)\n",
    "np.testing.assert_almost_equal(loss.value(ypred,y), -torch.log(torch.tensor([0.4,0.7])).sum(), decimal=8)\n",
    "np.testing.assert_array_almost_equal(loss.derivative(ypred,y), torch.tensor([[ 0.5000, -0.6000,  0.1000],[ 0.2000,  0.1000, -0.3000]]), decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ab724-6516-47ec-9aad-8a2a99a1e78f",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "As in previous' week PW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "da6cb457-1da9-4c14-83c2-345dfe0bf29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "b8a76b89-ea2c-4e26-a43d-874ca5b75e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f7fbd-b5fe-432d-b59e-732154aea809",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "Implement mini-batch gradient descent training loop. \n",
    "\n",
    "With the implementation of the two methods below you will be able to train and test the MLP:\n",
    "* train_epoch: for training the model over one epoch with per mini-batch updates\n",
    "* test_epoch: for evaluating the test/validation performance per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "69d69729-6a94-45a6-b6c6-9ecc7d4f2f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loss, dataloader, lr):\n",
    "    \"\"\"\n",
    "    Iterate over the mini-batches of one epoch, compute per mini-batch the forward and backward pass \n",
    "    and update the parameters. Also compute the loss and accuracy as an average over the epoch. \n",
    "    Note that this average includes per mini-batch updated model predictions and parameter updates.\n",
    "    model -- model to be trained\n",
    "    loss -- loss function to be used \n",
    "    dataloader -- data loader that provides mini-batches (from the training set)\n",
    "    lr -- learning rate to be used in the parameter updates     \n",
    "    returns loss, accuracy \n",
    "    \"\"\"\n",
    "    ### YOUR CODE START ###\n",
    "    nsamples = len(dataloader.dataset)\n",
    "    trainloss, correct = 0.0, 0\n",
    "    for X, y in dataloader:\n",
    "        batchsize = X.shape[0]\n",
    "        X = X.view(batchsize, -1)\n",
    "        z = model.forward(X)\n",
    "        batchloss = loss.value(z, y)\n",
    "        trainloss += batchloss.item()\n",
    "        correct += (z.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        dz = loss.derivative(z,y)\n",
    "        dx = model.backward(dz)\n",
    "        model.update(lr)\n",
    "    trainloss /= nsamples\n",
    "    correct /= nsamples\n",
    "    return trainloss, correct\n",
    "    ### YOUR CODE START ###\n",
    "\n",
    "\n",
    "def test_epoch(model, loss, dataloader):\n",
    "    \"\"\"\n",
    "    Iterate over the mini-batches of one epoch of the test set. Iterates over the mini-batches of the test set.\n",
    "    Estimates loss and accuracy as an average over the test (validation) set. The model is not updates here. \n",
    "    model -- model to be evaluated\n",
    "    loss -- loss function to be evaluated \n",
    "    dataloader -- data loader that provides mini-batches (from the test/validation set)\n",
    "    returns loss, accuracy \n",
    "    \"\"\"\n",
    "    nsamples = len(dataloader.dataset)\n",
    "    testloss, correct = 0.0, 0\n",
    "    for X, y in dataloader:\n",
    "        batchsize = X.shape[0]\n",
    "        X = X.view(batchsize, -1)\n",
    "        z = model.forward(X)\n",
    "        testloss += loss.value(z, y)\n",
    "        correct += (z.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    testloss /= nsamples\n",
    "    correct /= nsamples\n",
    "    return testloss, correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c7fe4-5c5f-40d4-a7b2-8f650140094f",
   "metadata": {},
   "source": [
    "### First Simple Check: Overfitting on Single Sample\n",
    "\n",
    "Load an arbitrary mini-batch from the training set. Train the model by using just this mini-batch.\n",
    "This is another test for checking whether your implementation is capable of learning something (see remark in week 2 of the course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "73f29756-4bba-473e-83e9-17996fe1b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "sample_batch, _ = torch.utils.data.random_split(train_data, [64, 60000-64])\n",
    "train_loader = DataLoader(sample_batch, batch_size=64, shuffle=False) # shuffling not needed since only one batch is used.\n",
    "\n",
    "sample_x,sample_y = next(iter(train_loader))\n",
    "print(sample_x.shape,sample_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9c9c8561-8484-48b2-9369-075f076fa983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Accuracy: 17.2%, Train Loss: 2.293502\n",
      "Epoch: 10, Train Accuracy: 21.9%, Train Loss: 2.188044\n",
      "Epoch: 20, Train Accuracy: 23.4%, Train Loss: 2.123873\n",
      "Epoch: 30, Train Accuracy: 28.1%, Train Loss: 2.053453\n",
      "Epoch: 40, Train Accuracy: 31.2%, Train Loss: 1.978773\n",
      "Epoch: 50, Train Accuracy: 31.2%, Train Loss: 1.892825\n",
      "Epoch: 60, Train Accuracy: 35.9%, Train Loss: 1.804102\n",
      "Epoch: 70, Train Accuracy: 39.1%, Train Loss: 1.729284\n",
      "Epoch: 80, Train Accuracy: 40.6%, Train Loss: 1.657540\n",
      "Epoch: 90, Train Accuracy: 42.2%, Train Loss: 1.597003\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1.0\n",
    "mlp = MLP(28*28, [100, 10])\n",
    "mseloss = CELoss()\n",
    "trainlosses = []\n",
    "trainaccs = []\n",
    "for t in range(epochs):\n",
    "    trainloss, trainacc = train_epoch(mlp, mseloss, train_loader, lr)\n",
    "    trainlosses.append(trainloss)\n",
    "    trainaccs.append(trainacc)\n",
    "    if t%10==0:\n",
    "        print(f\"Epoch: {t}, Train Accuracy: {(100*trainacc):>0.1f}%, Train Loss: {trainloss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2464995e-355c-4562-8619-7dea93e5d8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train Accuracy')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(torch.arange(epochs), trainlosses,\"b-\")\n",
    "plt.title(\"Train Loss\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(torch.arange(epochs), trainaccs,\"b-\")\n",
    "plt.ylim([0.0,1])\n",
    "plt.title(\"Train Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d366251-a20b-4aac-bc33-a4c09607078c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training with all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "32f164c3-0e81-478d-ac9e-c5770d55075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8ad2ab4f-b355-4fd3-9fad-7f27d3bd3a06",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Belg\\OneDrive - OST\\Master's\\02_Semester\\TSM_DeLearn\\tsm-delearn\\Exercise\\Week3\\pw03_backprop_stud-group_08.ipynb Cell 35'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000034?line=5'>6</a>\u001b[0m trainaccs, testaccs \u001b[39m=\u001b[39m [],[]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000034?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000034?line=8'>9</a>\u001b[0m     trainloss, trainacc \u001b[39m=\u001b[39m train_epoch(mlp, mseloss, train_loader, lr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000034?line=9'>10</a>\u001b[0m     testloss, testacc \u001b[39m=\u001b[39m test_epoch(mlp, mseloss, test_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000034?line=10'>11</a>\u001b[0m     trainlosses\u001b[39m.\u001b[39mappend(trainloss)\n",
      "\u001b[1;32mc:\\Users\\Belg\\OneDrive - OST\\Master's\\02_Semester\\TSM_DeLearn\\tsm-delearn\\Exercise\\Week3\\pw03_backprop_stud-group_08.ipynb Cell 28'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, loss, dataloader, lr)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000027?line=12'>13</a>\u001b[0m nsamples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000027?line=13'>14</a>\u001b[0m trainloss, correct \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000027?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000027?line=15'>16</a>\u001b[0m     batchsize \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000027?line=16'>17</a>\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mview(batchsize, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\datasets\\mnist.py:134\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/datasets/mnist.py?line=130'>131</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/datasets/mnist.py?line=132'>133</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/datasets/mnist.py?line=133'>134</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/datasets/mnist.py?line=135'>136</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/datasets/mnist.py?line=136'>137</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\transforms\\transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torchvision\\transforms\\functional.py:150\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/functional.py?line=147'>148</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/functional.py?line=148'>149</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/functional.py?line=149'>150</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39;49mdiv(\u001b[39m255\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/functional.py?line=150'>151</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/torchvision/transforms/functional.py?line=151'>152</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1.0\n",
    "mlp = MLP(28*28, [100,10])\n",
    "mseloss = CELoss()\n",
    "trainlosses, testlosses = [],[]\n",
    "trainaccs, testaccs = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    trainloss, trainacc = train_epoch(mlp, mseloss, train_loader, lr)\n",
    "    testloss, testacc = test_epoch(mlp, mseloss, test_loader)\n",
    "    trainlosses.append(trainloss)\n",
    "    testlosses.append(testloss)\n",
    "    trainaccs.append(trainacc)\n",
    "    testaccs.append(testacc)\n",
    "    print(f\"Epoch: {epoch}, Train Accuracy: {(100*trainacc):>0.1f}%, Train Loss: {trainloss:>8f}, Test Accuracy: {(100*testacc):>0.1f}%, Test Loss: {testloss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad1661-b9f4-4048-8196-6b76df0a5925",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Belg\\OneDrive - OST\\Master's\\02_Semester\\TSM_DeLearn\\tsm-delearn\\Exercise\\Week3\\pw03_backprop_stud-group_08.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000035?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000035?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(torch\u001b[39m.\u001b[39marange(epochs), trainlosses,\u001b[39m\"\u001b[39m\u001b[39mb-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000035?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(torch\u001b[39m.\u001b[39;49marange(epochs), testlosses,\u001b[39m\"\u001b[39;49m\u001b[39mr-\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000035?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mCE Loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Belg/OneDrive%20-%20OST/Master%27s/02_Semester/TSM_DeLearn/tsm-delearn/Exercise/Week3/pw03_backprop_stud-group_08.ipynb#ch0000035?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/pyplot.py?line=2754'>2755</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/pyplot.py?line=2755'>2756</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/pyplot.py?line=2756'>2757</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/pyplot.py?line=2757'>2758</a>\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/pyplot.py?line=2758'>2759</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1389'>1390</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1390'>1391</a>\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1391'>1392</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1628'>1629</a>\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1629'>1630</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1630'>1631</a>\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1631'>1632</a>\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1632'>1633</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_axes.py?line=1633'>1634</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=309'>310</a>\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=310'>311</a>\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=311'>312</a>\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:488\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=485'>486</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=486'>487</a>\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=487'>488</a>\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=488'>489</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/axes/_base.py?line=489'>490</a>\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1304\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1301'>1302</a>\u001b[0m \u001b[39m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1302'>1303</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1303'>1304</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1304'>1305</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1305'>1306</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1306'>1307</a>\u001b[0m         \u001b[39m# work around\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1307'>1308</a>\u001b[0m         \u001b[39m# https://github.com/pandas-dev/pandas/issues/27775 which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1318'>1319</a>\u001b[0m         \u001b[39m# This code should correctly identify and coerce to a\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/matplotlib/cbook/__init__.py?line=1319'>1320</a>\u001b[0m         \u001b[39m# numpy array all pandas versions.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/numpy/core/shape_base.py?line=62'>63</a>\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/numpy/core/shape_base.py?line=63'>64</a>\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/numpy/core/shape_base.py?line=64'>65</a>\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/numpy/core/shape_base.py?line=65'>66</a>\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/numpy/core/shape_base.py?line=66'>67</a>\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Python\\venv\\lib\\site-packages\\torch\\_tensor.py:678\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/torch/_tensor.py?line=675'>676</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/torch/_tensor.py?line=676'>677</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/torch/_tensor.py?line=677'>678</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/torch/_tensor.py?line=678'>679</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Belg/Python/venv/lib/site-packages/torch/_tensor.py?line=679'>680</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(torch.arange(epochs), trainlosses,\"b-\")\n",
    "plt.plot(torch.arange(epochs), testlosses,\"r-\")\n",
    "plt.title(\"CE Loss\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(torch.arange(epochs), trainaccs,\"b-\")\n",
    "plt.plot(torch.arange(epochs), testaccs,\"r-\")\n",
    "plt.ylim([0.7,1])\n",
    "plt.title(\"Accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
